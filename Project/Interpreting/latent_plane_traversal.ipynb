{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd3a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c145ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('./3dshapes.h5') :\n",
    "  print(\"file already exists\")\n",
    "else :\n",
    "    !wget https://storage.googleapis.com/3d-shapes/3dshapes.h5\n",
    "\n",
    "!ls -lh 3dshapes.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36640c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shapes3d(Dataset) :\n",
    "  def __init__(self, path) :\n",
    "    self.path = path\n",
    "    print(\"dataset to RAM\")\n",
    "    with h5py.File(path, 'r') as f :\n",
    "      self.images = f['images'][()]\n",
    "      self.labels = f['labels'][()]\n",
    "\n",
    "  def __len__(self) :\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self, idx) :\n",
    "    img = self.images[idx]\n",
    "    label = self.labels[idx]\n",
    "    img = torch.from_numpy(img).float()/ 255.0\n",
    "    img = img.permute(2, 0, 1)\n",
    "\n",
    "    return img, label\n",
    "\n",
    "dataset = Shapes3d('./3dshapes.h5')\n",
    "dataset_loader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44403960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "\n",
    "class BetaTCVAE(nn.Module) :\n",
    "  def __init__(self) :\n",
    "    super(BetaTCVAE, self).__init__()\n",
    "\n",
    "    # encoder\n",
    "    # (3, 64, 64)\n",
    "    self.conv1 = nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1)\n",
    "    # (32, 32, 32)\n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1)\n",
    "    # (64, 16, 16)\n",
    "    self.conv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
    "    # (128, 8, 8)\n",
    "    self.conv4 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n",
    "    # (256, 4, ,4)\n",
    "\n",
    "    self.hl1 = nn.Linear(256 * 4 * 4, 256)\n",
    "    self.hl2_mu = nn.Linear(256, 12) # mean\n",
    "    self.hl2_logvar = nn.Linear(256, 12) # log(variance)\n",
    "\n",
    "    #decoder\n",
    "    self.hl3 = nn.Linear(12, 256)\n",
    "    self.hl4 = nn.Linear(256, 256 * 4 * 4)\n",
    "\n",
    "    self.convT1 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT2 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT3 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT4 = nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "  def encode(self, x) :\n",
    "    c1 = F.leaky_relu(self.conv1(x))\n",
    "    c2 = F.leaky_relu(self.conv2(c1))\n",
    "    c3 = F.leaky_relu(self.conv3(c2))\n",
    "    c4 = F.leaky_relu(self.conv4(c3))\n",
    "    h1 = F.leaky_relu(self.hl1(c4.view(-1, 256 * 4 * 4)))\n",
    "    mu = self.hl2_mu(h1)\n",
    "    logvar = self.hl2_logvar(h1)\n",
    "    logvar = torch.clamp(logvar, min=-6.0, max=6.0)\n",
    "    return mu, logvar\n",
    "\n",
    "  def reparameterize(self, mu, logvar) :\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "  def decode(self, z) :\n",
    "    h3 = F.leaky_relu(self.hl3(z))\n",
    "    h4 = F.leaky_relu(self.hl4(h3))\n",
    "    cT1 = F.leaky_relu(self.convT1(h4.view(-1, 256, 4, 4)))\n",
    "    cT2 = F.leaky_relu(self.convT2(cT1))\n",
    "    cT3 = F.leaky_relu(self.convT3(cT2))\n",
    "    cT4 = torch.sigmoid(self.convT4(cT3))\n",
    "    img = torch.clamp(cT4, min=1e-6, max=1.0)\n",
    "    return img\n",
    "\n",
    "  def forward(self, x) :\n",
    "    mu, logvar = self.encode(x)\n",
    "    z = self.reparameterize(mu, logvar)\n",
    "    recon_x = self.decode(z)\n",
    "    return recon_x, z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BetaTCVAE()\n",
    "checkpoint = torch.load(\"/kaggle/input/betatcvae-shapes3d/final_model.pth\", map_location=torch.device(device))\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec62efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch curation\n",
    "\n",
    "def discretize(dataset) :\n",
    "    all_floats = np.array([data[1] for data in dataset])\n",
    "    all_uids = np.zeros_like(all_floats, dtype=int)\n",
    "\n",
    "    for i in range(6) :\n",
    "        _, all_uids[:, i] = np.unique(all_floats[:, i], return_inverse=True)\n",
    "\n",
    "    return all_uids\n",
    "\n",
    "class CuratedSampler :\n",
    "    def __init__(self, dataset, normal_criteria, outlier_criteria = {}) :\n",
    "        self.discrete = discretize(dataset)\n",
    "        self.dataset = dataset\n",
    "        self.normal_idx = []\n",
    "        self.outlier_idx = []\n",
    "\n",
    "        for idx in range(len(dataset)) :            \n",
    "            is_normal = True\n",
    "            for label_idx, normal_value in normal_criteria.items() :\n",
    "                if self.discrete[idx][label_idx] != normal_value :\n",
    "                    is_normal = False\n",
    "            if is_normal : self.normal_idx.append(idx)\n",
    "            else :\n",
    "                is_outlier = True\n",
    "                for label_idx, outlier_value in outlier_criteria.items() :\n",
    "                    if self.discrete[idx][label_idx] != outlier_value :\n",
    "                        is_outlier = False\n",
    "                if is_outlier : self.outlier_idx.append(idx)\n",
    "    \n",
    "    def get_batch(self, num_normal, device, num_outlier=0) :\n",
    "        normal_idxes = random.choices(self.normal_idx, k = num_normal)\n",
    "        outlier_idxes = random.choices(self.outlier_idx, k = num_outlier)\n",
    "        batch = []\n",
    "        for idx in normal_idxes :\n",
    "            batch.append(self.dataset[idx][0])\n",
    "        for idx in outlier_idxes :\n",
    "            batch.append(self.dataset[idx][0])\n",
    "            \n",
    "        return torch.stack(batch).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed0ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "curator = CuratedSampler(dataset, {})\n",
    "batch = curator.get_batch(100, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d0f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_traversal(batch, dim1, dim2, rows = 21, cols = 21) :\n",
    "    \n",
    "    with torch.no_grad() :\n",
    "        _, _, mu, _ = model(batch)\n",
    "        base = mu[25].clone().unsqueeze(0)\n",
    "\n",
    "    path_range = torch.linspace(-2, 2, steps= rows).to(device)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(rows, cols))\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for row in range(rows) :\n",
    "        z_ = base.clone()\n",
    "        z_[0, dim1] = path_range[row]\n",
    "        for col in range(cols) :\n",
    "            z_[0, dim2] = path_range[col]\n",
    "\n",
    "            with torch.no_grad() :\n",
    "                img = model.decode(z_)\n",
    "\n",
    "            ax = axes[row, col]\n",
    "            ax.imshow(img[0].cpu().permute(1, 2, 0).squeeze().numpy())\n",
    "            ax.axis('off')\n",
    "\n",
    "    fig.suptitle(f\"2D matrix of changes in latent code index {dim1} and {dim2} \\nX - axis is latent code {dim1} and Y-axis is latent code {dim2}\")\n",
    "    plt.show()\n",
    "    \n",
    "shape_traversal(batch, 5, 10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
