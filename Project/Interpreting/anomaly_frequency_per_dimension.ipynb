{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1922434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47823de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('./3dshapes.h5') :\n",
    "  print(\"file already exi\")\n",
    "else :\n",
    "    !wget https://storage.googleapis.com/3d-shapes/3dshapes.h5\n",
    "\n",
    "!ls -lh 3dshapes.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d62cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shapes3d(Dataset) :\n",
    "  def __init__(self, path) :\n",
    "    self.path = path\n",
    "    print(\"dataset to RAM\")\n",
    "    with h5py.File(path, 'r') as f :\n",
    "      self.images = f['images'][()]\n",
    "      self.labels = f['labels'][()]\n",
    "\n",
    "  def __len__(self) :\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self, idx) :\n",
    "    img = self.images[idx]\n",
    "    label = self.labels[idx]\n",
    "    img = torch.from_numpy(img).float()/ 255.0\n",
    "    img = img.permute(2, 0, 1)\n",
    "\n",
    "    return img, label\n",
    "\n",
    "dataset = Shapes3d('./3dshapes.h5')\n",
    "dataset_loader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3675984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "\n",
    "class BetaTCVAE(nn.Module) :\n",
    "  def __init__(self) :\n",
    "    super(BetaTCVAE, self).__init__()\n",
    "\n",
    "    # encoder\n",
    "    # (3, 64, 64)\n",
    "    self.conv1 = nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1)\n",
    "    # (32, 32, 32)\n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1)\n",
    "    # (64, 16, 16)\n",
    "    self.conv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
    "    # (128, 8, 8)\n",
    "    self.conv4 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n",
    "    # (256, 4, ,4)\n",
    "\n",
    "    self.hl1 = nn.Linear(256 * 4 * 4, 256)\n",
    "    self.hl2_mu = nn.Linear(256, 12) # mean\n",
    "    self.hl2_logvar = nn.Linear(256, 12) # log(variance)\n",
    "\n",
    "    #decoder\n",
    "    self.hl3 = nn.Linear(12, 256)\n",
    "    self.hl4 = nn.Linear(256, 256 * 4 * 4)\n",
    "\n",
    "    self.convT1 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT2 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT3 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT4 = nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "  def encode(self, x) :\n",
    "    c1 = F.leaky_relu(self.conv1(x))\n",
    "    c2 = F.leaky_relu(self.conv2(c1))\n",
    "    c3 = F.leaky_relu(self.conv3(c2))\n",
    "    c4 = F.leaky_relu(self.conv4(c3))\n",
    "    h1 = F.leaky_relu(self.hl1(c4.view(-1, 256 * 4 * 4)))\n",
    "    mu = self.hl2_mu(h1)\n",
    "    logvar = self.hl2_logvar(h1)\n",
    "    logvar = torch.clamp(logvar, min=-6.0, max=6.0)\n",
    "    return mu, logvar\n",
    "\n",
    "  def reparameterize(self, mu, logvar) :\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "  def decode(self, z) :\n",
    "    h3 = F.leaky_relu(self.hl3(z))\n",
    "    h4 = F.leaky_relu(self.hl4(h3))\n",
    "    cT1 = F.leaky_relu(self.convT1(h4.view(-1, 256, 4, 4)))\n",
    "    cT2 = F.leaky_relu(self.convT2(cT1))\n",
    "    cT3 = F.leaky_relu(self.convT3(cT2))\n",
    "    cT4 = torch.sigmoid(self.convT4(cT3))\n",
    "    img = torch.clamp(cT4, min=1e-6, max=1.0)\n",
    "    return img\n",
    "\n",
    "  def forward(self, x) :\n",
    "    mu, logvar = self.encode(x)\n",
    "    z = self.reparameterize(mu, logvar)\n",
    "    recon_x = self.decode(z)\n",
    "    return recon_x, z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34a072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BetaTCVAE()\n",
    "checkpoint = torch.load(\"/kaggle/input/betatcvae-shapes3d/final_model.pth\", map_location=torch.device(device))\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "torch.no_grad()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c30382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch curation\n",
    "\n",
    "def discretize(dataset) :\n",
    "    all_floats = np.array([data[1] for data in dataset])\n",
    "    all_uids = np.zeros_like(all_floats, dtype=int)\n",
    "\n",
    "    for i in range(6) :\n",
    "        _, all_uids[:, i] = np.unique(all_floats[:, i], return_inverse=True)\n",
    "\n",
    "    return all_uids\n",
    "\n",
    "class CuratedSampler :\n",
    "    def __init__(self, dataset, normal_criteria, outlier_criteria) :\n",
    "        self.discrete = discretize(dataset)\n",
    "        self.dataset = dataset\n",
    "        self.normal_idx = []\n",
    "        self.outlier_idx = []\n",
    "\n",
    "        for idx in range(len(dataset)) :            \n",
    "            is_normal = True\n",
    "            for label_idx, normal_value in normal_criteria.items() :\n",
    "                if self.discrete[idx][label_idx] != normal_value :\n",
    "                    is_normal = False\n",
    "            if is_normal : self.normal_idx.append(idx)\n",
    "            else :\n",
    "                is_outlier = True\n",
    "                for label_idx, outlier_value in outlier_criteria.items() :\n",
    "                    if self.discrete[idx][label_idx] != outlier_value :\n",
    "                        is_outlier = False\n",
    "                if is_outlier : self.outlier_idx.append(idx)\n",
    "    \n",
    "    def get_batch(self, num_normal, num_outlier, device) :\n",
    "        normal_idxes = random.choices(self.normal_idx, k = num_normal)\n",
    "        outlier_idxes = random.choices(self.outlier_idx, k = num_outlier)\n",
    "        batch = []\n",
    "        for idx in normal_idxes :\n",
    "            batch.append(self.dataset[idx][0])\n",
    "        for idx in outlier_idxes :\n",
    "            batch.append(self.dataset[idx][0])\n",
    "            \n",
    "        return torch.stack(batch).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc060d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_criteria = {1: 3, 4: 2, 2 : 5}\n",
    "outlier_criteria = {}\n",
    "num_normals = 300\n",
    "num_outliers = 20\n",
    "curator = CuratedSampler(dataset, normal_criteria, outlier_criteria)\n",
    "batch = curator.get_batch(num_normals, num_outliers, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb8ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_z_scores(input_data) :\n",
    "    batch_z, _ = model.encode(input_data)\n",
    "    loo_z_scores = []\n",
    "    num_samples = input_data.size(0)\n",
    "    for i in range(num_samples) :\n",
    "        mask = torch.ones(num_samples, dtype=bool)\n",
    "        mask[i] = False\n",
    "        curr_samples = batch_z[mask]\n",
    "        test_sample = batch_z[i:i+1]\n",
    "        mu = curr_samples.mean(dim=0)\n",
    "        std = curr_samples.std(dim=0)\n",
    "        std = torch.where(std < 1e-6, torch.ones_like(std), std)\n",
    "        z_score = (test_sample - mu) / std\n",
    "        loo_z_scores.append(z_score)\n",
    "    z_scores = torch.vstack(loo_z_scores)\n",
    "    return z_scores\n",
    "\n",
    "def calculate_MD(input_data) :\n",
    "    batch_z, _ = model.encode(input_data)\n",
    "    loo_md = []\n",
    "    n_samples = input_data.size(0)\n",
    "    for i in range(n_samples) :\n",
    "        mask = torch.ones(n_samples, dtype=bool)\n",
    "        mask[i] = False\n",
    "        curr_samples = batch_z[mask]\n",
    "        test_sample = batch_z[i:i+1]\n",
    "        mu = curr_samples.mean(dim=0)\n",
    "        covar = torch.cov(curr_samples.T)\n",
    "        inv_covar = torch.linalg.pinv(covar)\n",
    "        disp_vec = test_sample - mu\n",
    "        dist = torch.sqrt((disp_vec @ inv_covar @ disp_vec.T).squeeze())\n",
    "        loo_md.append(dist)\n",
    "    distances = torch.tensor([d.item() for d in loo_md]).to(device)\n",
    "    return distances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a436d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = calculate_z_scores(batch)\n",
    "distances = calculate_MD(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d47f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = distances.cpu().numpy()\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(distances, bins=20, alpha=1, color=\"blue\", density=True)\n",
    "plt.title(\"Mahlanobis Distance Distribution\")\n",
    "plt.xlabel(\"MD Score (lower is normal)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def differentiate_batch(batch, distances, threshold) :\n",
    "    if not isinstance(distances, torch.Tensor) :\n",
    "        distances = torch.tensor(distances, device= batch.device)\n",
    "    mask = distances > threshold\n",
    "    outliers = batch[mask]\n",
    "    normals = batch[~mask]\n",
    "    normal_indices = torch.nonzero(~mask, as_tuple=True)[0]\n",
    "    outlier_indices = torch.nonzero(mask, as_tuple=True)[0]\n",
    "    return outliers, normals, outlier_indices, normal_indices\n",
    "\n",
    "def generate_counterfactual(batch, normal_idxes, outlier_idx, z_scores) :\n",
    "    batch_z, _ = model.encode(batch)\n",
    "    outlier_dimension = torch.argmax(torch.abs(z_scores[outlier_idx])).cpu().numpy()\n",
    "    mu = torch.mean(batch_z[normal_idxes], dim=0)\n",
    "    counterfactual = batch_z[outlier_idx].clone()\n",
    "    counterfactual[outlier_dimension] = mu[outlier_dimension]\n",
    "    original_img = batch[outlier_idx]\n",
    "    counterfactual_img = model.decode(counterfactual.unsqueeze(0))\n",
    "    fig, axes = plt.subplots(1, 11, figsize=(15, 15))\n",
    "    for i in range(11) :\n",
    "        img_z = batch_z[outlier_idx] * (1 - i/10) + counterfactual * (i/10)\n",
    "        img = model.decode(img_z)\n",
    "        axes[i].imshow(img.squeeze().permute(1, 2, 0).detach().cpu().numpy())\n",
    "        if i == 0 :\n",
    "            axes[i].set_title(\"original outlier\")\n",
    "        if i == 10 :\n",
    "            axes[i].set_title(\"counterfactual image\")\n",
    "        axes[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we infer the threshold from the above produced histogram\n",
    "threshold = 7\n",
    "_, _, outlier_idxes, normal_idxes = differentiate_batch(batch, distances, threshold)\n",
    "\n",
    "outlier_z = z_scores[outlier_idxes]\n",
    "outlier_dimension = torch.argmax(torch.abs(outlier_z), dim=1).cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(outlier_dimension, bins=range(outlier_z.shape[1] + 1), \n",
    "         align='left', rwidth=0.8, color='teal', alpha=0.7, density=False)\n",
    "plt.title(\"Anomaly Distribution across Dimmensions in Latent Space\")\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xticks(range(outlier_z.shape[1]))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e24e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_counterfactual(batch, normal_idxes, outlier_idxes[0], z_scores)\n",
    "generate_counterfactual(batch, normal_idxes, outlier_idxes[1], z_scores)\n",
    "generate_counterfactual(batch, normal_idxes, outlier_idxes[2], z_scores)\n",
    "generate_counterfactual(batch, normal_idxes, outlier_idxes[3], z_scores)\n",
    "generate_counterfactual(batch, normal_idxes, outlier_idxes[4], z_scores)\n",
    "generate_counterfactual(batch, normal_idxes, outlier_idxes[5], z_scores)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
