{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be6fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('./3dshapes.h5') :\n",
    "  print(\"dataset already exists\")\n",
    "else :\n",
    "  !wget https://storage.googleapis.com/3d-shapes/3dshapes.h5\n",
    "\n",
    "!ls -lh 3dshapes.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f883540",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shapes3d(Dataset) :\n",
    "  def __init__(self, path) :\n",
    "    self.path = path\n",
    "    print(\"dataset to RAM\")\n",
    "    with h5py.File(path, 'r') as f :\n",
    "      self.images = f['images'][()]\n",
    "      self.labels = f['labels'][()]\n",
    "\n",
    "  def __len__(self) :\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self, idx) :\n",
    "    img = self.images[idx]\n",
    "    label = self.labels[idx]\n",
    "    img = torch.from_numpy(img).float()/ 255.0\n",
    "    img = img.permute(2, 0, 1)\n",
    "\n",
    "    return img, label\n",
    "\n",
    "dataset = Shapes3d('./3dshapes.h5')\n",
    "dataset_loader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93de0d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "\n",
    "class BetaTCVAE(nn.Module) :\n",
    "  \n",
    "  def __init__(self) :\n",
    "    super(BetaTCVAE, self).__init__()\n",
    "\n",
    "    # encoder\n",
    "    # (3, 64, 64)\n",
    "    self.conv1 = nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1)\n",
    "    # (32, 32, 32)\n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1)\n",
    "    # (64, 16, 16)\n",
    "    self.conv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
    "    # (128, 8, 8)\n",
    "    self.conv4 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n",
    "    # (256, 4, ,4)\n",
    "\n",
    "    self.hl1 = nn.Linear(256 * 4 * 4, 256)\n",
    "    self.hl2_mu = nn.Linear(256, 12) # mean\n",
    "    self.hl2_logvar = nn.Linear(256, 12) # log(variance)\n",
    "\n",
    "    #decoder\n",
    "    self.hl3 = nn.Linear(12, 256)\n",
    "    self.hl4 = nn.Linear(256, 256 * 4 * 4)\n",
    "\n",
    "    self.convT1 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT2 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT3 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT4 = nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "  def encode(self, x) :\n",
    "    c1 = F.leaky_relu(self.conv1(x))\n",
    "    c2 = F.leaky_relu(self.conv2(c1))\n",
    "    c3 = F.leaky_relu(self.conv3(c2))\n",
    "    c4 = F.leaky_relu(self.conv4(c3))\n",
    "    h1 = F.leaky_relu(self.hl1(c4.view(-1, 256 * 4 * 4)))\n",
    "    mu = self.hl2_mu(h1)\n",
    "    logvar = self.hl2_logvar(h1)\n",
    "    logvar = torch.clamp(logvar, min=-6.0, max=6.0)\n",
    "    return mu, logvar\n",
    "\n",
    "  def reparameterize(self, mu, logvar) :\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "  def decode(self, z) :\n",
    "    h3 = F.leaky_relu(self.hl3(z))\n",
    "    h4 = F.leaky_relu(self.hl4(h3))\n",
    "    cT1 = F.leaky_relu(self.convT1(h4.view(-1, 256, 4, 4)))\n",
    "    cT2 = F.leaky_relu(self.convT2(cT1))\n",
    "    cT3 = F.leaky_relu(self.convT3(cT2))\n",
    "    cT4 = torch.sigmoid(self.convT4(cT3))\n",
    "    img = torch.clamp(cT4, min=1e-6, max=1.0)\n",
    "    return img\n",
    "\n",
    "  def forward(self, x) :\n",
    "    mu, logvar = self.encode(x)\n",
    "    z = self.reparameterize(mu, logvar)\n",
    "    recon_x = self.decode(z)\n",
    "    return recon_x, z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c052b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BetaTCVAE()\n",
    "checkpoint = torch.load(\"/kaggle/input/betatcvae-shapes3d/final_model.pth\", map_location=torch.device(device))\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "torch.no_grad()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d3821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MD(input_data) :\n",
    "    batch_z, _ = model.encode(input_data)\n",
    "    loo_md = []\n",
    "    n_samples = input_data.size(0)\n",
    "    for i in range(n_samples) :\n",
    "        mask = torch.ones(n_samples, dtype=bool)\n",
    "        mask[i] = False\n",
    "        curr_samples = batch_z[mask]\n",
    "        test_sample = batch_z[i:i+1]\n",
    "        mu = curr_samples.mean(dim=0)\n",
    "        covar = torch.cov(curr_samples.T)\n",
    "        inv_covar = torch.linalg.pinv(covar)\n",
    "        disp_vec = test_sample - mu\n",
    "        dist = torch.sqrt((disp_vec @ inv_covar @ disp_vec.T).squeeze())\n",
    "        loo_md.append(dist)\n",
    "    distances = torch.tensor([d.item() for d in loo_md]).to(device)\n",
    "    return distances\n",
    "\n",
    "def recon_loss(input_data) :\n",
    "    recon_input, _, _, _ = model(input_data)\n",
    "    loss_per_pixel = F.binary_cross_entropy(recon_input, input_data, reduction='none')\n",
    "    loss_per_image = loss_per_pixel.view(loss_per_pixel.size(0), -1).sum(dim=1)\n",
    "    loss_fracn = loss_per_image / loss_per_image.sum()\n",
    "    return loss_fracn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a490ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(dataset) :\n",
    "    all_floats = np.array([data[1] for data in dataset])\n",
    "    all_uids = np.zeros_like(all_floats, dtype=int)\n",
    "\n",
    "    for i in range(6) :\n",
    "        _, all_uids[:, i] = np.unique(all_floats[:, i], return_inverse=True)\n",
    "\n",
    "    return all_uids\n",
    "\n",
    "class CuratedSampler :\n",
    "    def __init__(self, dataset, normal_criteria, outlier_criteria) :\n",
    "        self.discrete = discretize(dataset)\n",
    "        self.dataset = dataset\n",
    "        self.normal_idx = []\n",
    "        self.outlier_idx = []\n",
    "\n",
    "        for idx in range(len(dataset)) :            \n",
    "            is_normal = True\n",
    "            for label_idx, normal_value in normal_criteria.items() :\n",
    "                if self.discrete[idx][label_idx] != normal_value :\n",
    "                    is_normal = False\n",
    "            if is_normal : self.normal_idx.append(idx)\n",
    "            else :\n",
    "                is_outlier = True\n",
    "                for label_idx, outlier_value in outlier_criteria.items() :\n",
    "                    if self.discrete[idx][label_idx] != outlier_value :\n",
    "                        is_outlier = False\n",
    "                if is_outlier : self.outlier_idx.append(idx)\n",
    "    \n",
    "    def get_batch(self, num_normal, num_outlier, device) :\n",
    "        normal_idxes = random.choices(self.normal_idx, k = num_normal)\n",
    "        outlier_idxes = random.choices(self.outlier_idx, k = num_outlier)\n",
    "        batch = []\n",
    "        for idx in normal_idxes :\n",
    "            batch.append(self.dataset[idx][0])\n",
    "        for idx in outlier_idxes :\n",
    "            batch.append(self.dataset[idx][0])\n",
    "            \n",
    "        return torch.stack(batch).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a98bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_criteria = {1: 3, 4: 2, 2 : 5}\n",
    "outlier_criteria = {}\n",
    "\n",
    "curator = CuratedSampler(dataset, normal_criteria, outlier_criteria)\n",
    "batch = curator.get_batch(325, 25, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd30b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = calculate_MD(batch)\n",
    "recon_frac = recon_loss(batch)\n",
    "\n",
    "distances = distances.cpu().numpy()\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(distances[:325], bins=20, alpha=0.6, color=\"blue\", label=\"Normal\", density=True)\n",
    "plt.hist(distances[325:], bins=20, alpha=0.6, color='red', label=\"Outlier\", density=True)\n",
    "plt.title(\"Mahlanobis Distance Distribution\")\n",
    "plt.xlabel(\"MD Score (lower is normal)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7349dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = calculate_MD(batch)\n",
    "recon_frac = recon_loss(batch)\n",
    "print(distances)\n",
    "print(recon_frac)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "axes[0].plot(distances.cpu().numpy())\n",
    "axes[1].plot(recon_frac.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def auroc(normal_scores, outlier_scores) :\n",
    "    y_true = [0] * len(normal_scores) + [1] * len(outlier_scores)\n",
    "    y_scores = list(normal_scores) + list(outlier_scores)\n",
    "    score = roc_auc_score(y_true, y_scores)\n",
    "    return score\n",
    "\n",
    "score = auroc(distances[:325], distances[325:])\n",
    "print(f\"{score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
