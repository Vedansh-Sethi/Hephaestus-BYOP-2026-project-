{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5229d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e62d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('./3dshapes.h5') :\n",
    "  os.remove('./3dshapes.h5')\n",
    "\n",
    "!wget https://storage.googleapis.com/3d-shapes/3dshapes.h5\n",
    "\n",
    "!ls -lh 3dshapes.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a0be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shapes3d(Dataset) :\n",
    "  def __init__(self, path) :\n",
    "    self.path = path\n",
    "    print(\"dataset to RAM\")\n",
    "    with h5py.File(path, 'r') as f :\n",
    "      self.images = f['images'][()]\n",
    "      self.labels = f['labels'][()]\n",
    "\n",
    "  def __len__(self) :\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self, idx) :\n",
    "    img = self.images[idx]\n",
    "    img = torch.from_numpy(img).float()/ 255.0\n",
    "    img = img.permute(2, 0, 1)\n",
    "\n",
    "    return img\n",
    "\n",
    "dataset = Shapes3d('./3dshapes.h5')\n",
    "dataset_loader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "\n",
    "class BetaTCVAE(nn.Module) :\n",
    "  def __init__(self) :\n",
    "    super(BetaTCVAE, self).__init__()\n",
    "\n",
    "    # encoder\n",
    "    # (3, 64, 64)\n",
    "    self.conv1 = nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1)\n",
    "    # (32, 32, 32)\n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1)\n",
    "    # (64, 16, 16)\n",
    "    self.conv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
    "    # (128, 8, 8)\n",
    "    self.conv4 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n",
    "    # (256, 4, ,4)\n",
    "\n",
    "    self.hl1 = nn.Linear(256 * 4 * 4, 256)\n",
    "    self.hl2_mu = nn.Linear(256, 12) # mean\n",
    "    self.hl2_logvar = nn.Linear(256, 12) # log(variance)\n",
    "\n",
    "    #decoder\n",
    "    self.hl3 = nn.Linear(12, 256)\n",
    "    self.hl4 = nn.Linear(256, 256 * 4 * 4)\n",
    "\n",
    "    self.convT1 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT2 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT3 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT4 = nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "  def encode(self, x) :\n",
    "    c1 = F.leaky_relu(self.conv1(x))\n",
    "    c2 = F.leaky_relu(self.conv2(c1))\n",
    "    c3 = F.leaky_relu(self.conv3(c2))\n",
    "    c4 = F.leaky_relu(self.conv4(c3))\n",
    "    h1 = F.leaky_relu(self.hl1(c4.view(-1, 256 * 4 * 4)))\n",
    "    mu = self.hl2_mu(h1)\n",
    "    logvar = self.hl2_logvar(h1)\n",
    "    logvar = torch.clamp(logvar, min=-6.0, max=6.0)\n",
    "    return mu, logvar\n",
    "\n",
    "  def reparameterize(self, mu, logvar) :\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "  def decode(self, z) :\n",
    "    h3 = F.leaky_relu(self.hl3(z))\n",
    "    h4 = F.leaky_relu(self.hl4(h3))\n",
    "    cT1 = F.leaky_relu(self.convT1(h4.view(-1, 256, 4, 4)))\n",
    "    cT2 = F.leaky_relu(self.convT2(cT1))\n",
    "    cT3 = F.leaky_relu(self.convT3(cT2))\n",
    "    cT4 = torch.sigmoid(self.convT4(cT3))\n",
    "    img = torch.clamp(cT4, min=1e-6, max=1.0)\n",
    "    return img\n",
    "\n",
    "  def forward(self, x) :\n",
    "    mu, logvar = self.encode(x)\n",
    "    z = self.reparameterize(mu, logvar)\n",
    "    recon_x = self.decode(z)\n",
    "    return recon_x, z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390af7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "TRAINING_BATCHES = 500\n",
    "LR = 5e-4\n",
    "EPOCHS = 50\n",
    "GAMMA = 1.0\n",
    "BETA = 6.0\n",
    "ANNEAL_STEPS = 5000\n",
    "\n",
    "model = BetaTCVAE()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "def log_density_gaussian(z, mu, logvar) :\n",
    "  norm = -0.5 * (math.log(2 * math.pi) + logvar)\n",
    "  log_density = norm - 0.5 * ((z - mu) ** 2 * torch.exp(-logvar))\n",
    "  return log_density\n",
    "\n",
    "def BCE_loss_function(recon_x, x) :\n",
    "  BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "  return BCE\n",
    "\n",
    "def log_q_zx(z, mu, logvar) :\n",
    "  log_q_zx = log_density_gaussian(z, mu, logvar)\n",
    "  return log_q_zx.sum(dim=1)\n",
    "\n",
    "def log_p_z(z) :\n",
    "  standard = torch.zeros_like(z)\n",
    "  log_p_z = log_density_gaussian(z, standard, standard)\n",
    "  return log_p_z.sum(dim=1)\n",
    "\n",
    "def initialize_weights(batch_size=BATCH_SIZE, dataset_size = len(dataset)) :\n",
    "  stratified_weight = (dataset_size - batch_size + 1) / (dataset_size * (batch_size - 1))\n",
    "  weight_arr = torch.full((batch_size, batch_size), stratified_weight)\n",
    "  weight_arr.view(-1)[::batch_size + 1] = 1.0 / dataset_size\n",
    "  return weight_arr\n",
    "\n",
    "def mat_log_q_z(batch_z, batch_mu, batch_logvar, batch_size=BATCH_SIZE, latent_dim=12) :\n",
    "  mat_log_q_z = log_density_gaussian(batch_z.view(1, batch_size, latent_dim),\n",
    "                                     batch_mu.view(batch_size, 1, latent_dim),\n",
    "                                     batch_logvar.view(batch_size, 1, latent_dim))\n",
    "  return mat_log_q_z\n",
    "\n",
    "def loss_function(num_iters, recon_batch, batch, batch_z, batch_mu, batch_logvar) :\n",
    "  mat_log_q_z_val = mat_log_q_z(batch_z, batch_mu, batch_logvar)\n",
    "  log_p_z_val = log_p_z(batch_z)\n",
    "  log_q_zx_val = log_q_zx(batch_z, batch_mu, batch_logvar)\n",
    "  BCE = BCE_loss_function(recon_batch, batch)\n",
    "\n",
    "  weights = initialize_weights()\n",
    "  weights = weights.to(device)\n",
    "  log_weights = torch.log(weights + 1e-10)\n",
    "\n",
    "  # mat_log_q_z_val shape : [128, 128, 12]\n",
    "\n",
    "  log_joint_prob = mat_log_q_z_val.sum(2) + log_weights\n",
    "  # log_joint_prob shape : [128, 128]\n",
    "  # [i, j] is the probability that x_i generated latent code z_j\n",
    "  log_q_z = torch.logsumexp(log_joint_prob, dim=1, keepdim=False)\n",
    "  # log_q_z shape : [128]\n",
    "  # it is a density map of the latent codees of the batch\n",
    "\n",
    "  log_marg_prob = mat_log_q_z_val + log_weights.view(BATCH_SIZE, BATCH_SIZE, 1)\n",
    "  # log_marg_prob shape : [128, 128, 12]\n",
    "  # probability of each component of each latent code occuring individually in each picture's distibution\n",
    "  log_prod_q_z = torch.logsumexp(log_marg_prob, dim=1, keepdim=False).sum(1)\n",
    "  # log_prod_q_z shape : [128]\n",
    "  # i'th entry is product of marginal probability of occurence each component of z_i\n",
    "\n",
    "  mi_loss = (log_q_zx_val - log_q_z).sum()\n",
    "  tc_loss = (log_q_z - log_prod_q_z).sum()\n",
    "  dwkl_loss = (log_prod_q_z - log_p_z_val).sum()\n",
    "\n",
    "  gamma_ratio = min(1.0 * num_iters/ANNEAL_STEPS, 1.0)\n",
    "\n",
    "  loss = BCE + mi_loss + BETA * tc_loss + gamma_ratio * GAMMA * dwkl_loss\n",
    "  return loss, BCE, mi_loss, tc_loss, dwkl_loss# initialization of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5950cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "train_bce_losses = []\n",
    "train_mi_losses = []\n",
    "train_tc_losses = []\n",
    "train_dwkl_losses = []\n",
    "\n",
    "num_iters = 0\n",
    "\n",
    "print(f\"using device {device}\")\n",
    "print(\"Training started -\")\n",
    "\n",
    "for epoch in range(EPOCHS) :\n",
    "  overall_BCE_loss = 0\n",
    "  overall_tc_loss = 0\n",
    "  overall_mi_loss = 0\n",
    "  overall_dwkl_loss = 0\n",
    "\n",
    "  for batch_idx, data in enumerate(dataset_loader) :\n",
    "    num_iters += 1\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    recon_batch, batch_z, batch_mu, batch_logvar = model(data)\n",
    "    loss, bce_loss, mi_loss, tc_loss, dwkl_loss = loss_function(num_iters, recon_batch, data, batch_z, batch_mu, batch_logvar)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    overall_BCE_loss += bce_loss.item()\n",
    "    overall_tc_loss += tc_loss.item()\n",
    "    overall_mi_loss += mi_loss.item()\n",
    "    overall_dwkl_loss += dwkl_loss.item()\n",
    "\n",
    "    if batch_idx > TRAINING_BATCHES :\n",
    "      break\n",
    "\n",
    "  average_bce_loss = overall_BCE_loss / TRAINING_BATCHES\n",
    "  average_tc_loss = overall_tc_loss / TRAINING_BATCHES\n",
    "  average_mi_loss = overall_mi_loss / TRAINING_BATCHES\n",
    "  average_dwkl_loss = overall_dwkl_loss / TRAINING_BATCHES\n",
    "  train_bce_losses.append(average_bce_loss)\n",
    "  train_tc_losses.append(average_tc_loss)\n",
    "  train_mi_losses.append(average_mi_loss)\n",
    "  train_dwkl_losses.append(average_dwkl_loss)\n",
    "  print(f\"epoch : {epoch}\")\n",
    "  print(f\"BCE loss : {average_bce_loss:.2f}\\tMI loss : {average_mi_loss:.2f}\")\n",
    "  print(f\"TC loss (per image) : {average_tc_loss/BATCH_SIZE:.2f}\\tDWKL loss (per image) : {average_dwkl_loss/BATCH_SIZE:.2f}\")\n",
    "  print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Training finished\")\n",
    "save_path = \"./model_weights_tcvae.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model weights saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].plot(train_dwkl_losses, label='DWKL loss')\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"DWKL loss\")\n",
    "axes[0].set_title(\"Dimension wise KL loss\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[1].plot(train_tc_losses, label='TC loss')\n",
    "axes[1].plot(train_mi_losses, label='MI loss')\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"loss\")\n",
    "axes[1].set_title(\"TC and MI losses\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_bce_losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"BCE loss\")\n",
    "plt.title(\"BCE loss\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "iterable = iter(dataset_loader)\n",
    "\n",
    "with torch.no_grad() :\n",
    "  x = next(iterable)\n",
    "  x = x.to(device)\n",
    "  recon_batch, _, mu, logvar = model(x)\n",
    "\n",
    "fig, axes = plt.subplots(2, 10, figsize=(15, 4))\n",
    "\n",
    "for i in range(10) :\n",
    "  original = x[i].cpu().permute(1, 2, 0).squeeze().numpy()\n",
    "  axes[0, i].imshow(original)\n",
    "  axes[0, i].axis('off')\n",
    "  if i == 5 : axes[0, i].set_title(\"original images\")\n",
    "  recon = recon_batch[i].cpu().permute(1, 2, 0).squeeze().numpy()\n",
    "  axes[1, i].imshow(recon)\n",
    "  axes[1, i].axis('off')\n",
    "  if i == 5 : axes[1, i].set_title(\"reconstructed images\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea0442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_traversal(model, iterable, dims=12, steps=12) :\n",
    "  model.eval()\n",
    "  data = next(iterable)\n",
    "  data = data.to(device)\n",
    "\n",
    "  with torch.no_grad() :\n",
    "    _, _, mu, _ = model(data)\n",
    "    base = mu[0].clone().unsqueeze(0)\n",
    "\n",
    "  path_range = torch.linspace(-3, 3, steps=steps).to(device)\n",
    "\n",
    "  fig, axes = plt.subplots(dims, steps, figsize=(steps, dims))\n",
    "  plt.subplots_adjust(wspace = 0.05, hspace = 0.05)\n",
    "\n",
    "  for dim in range(dims) :\n",
    "    for step in range(steps) :\n",
    "\n",
    "      z_ = base.clone()\n",
    "      z_[0, dim] = path_range[step]\n",
    "\n",
    "      with torch.no_grad() :\n",
    "        recon_img = model.decode(z_)\n",
    "\n",
    "      ax = axes[dim, step]\n",
    "      img = recon_img[0].cpu().permute(1, 2, 0).squeeze().numpy()\n",
    "      ax.imshow(img)\n",
    "      ax.axis('off')\n",
    "\n",
    "  plt.suptitle(f\"Latent Traversals\", fontsize=16)\n",
    "  plt.show()\n",
    "\n",
    "visualize_traversal(model, iterable)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
