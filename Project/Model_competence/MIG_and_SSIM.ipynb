{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('./3dshapes.h5') :\n",
    "  os.remove('./3dshapes.h5')\n",
    "\n",
    "!wget https://storage.googleapis.com/3d-shapes/3dshapes.h5\n",
    "\n",
    "!ls -lh 3dshapes.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852241b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shapes3d(Dataset) :\n",
    "  def __init__(self, path) :\n",
    "    self.path = path\n",
    "    print(\"dataset to RAM\")\n",
    "    with h5py.File(path, 'r') as f :\n",
    "      self.images = f['images'][()]\n",
    "      self.labels = f['labels'][()]\n",
    "\n",
    "  def __len__(self) :\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self, idx) :\n",
    "    img = self.images[idx]\n",
    "    label = self.labels[idx]\n",
    "    img = torch.from_numpy(img).float()/ 255.0\n",
    "    img = img.permute(2, 0, 1)\n",
    "\n",
    "    return img, label\n",
    "\n",
    "dataset = Shapes3d('./3dshapes.h5')\n",
    "dataset_loader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f011ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "\n",
    "class BetaTCVAE(nn.Module) :\n",
    "  def __init__(self) :\n",
    "    super(BetaTCVAE, self).__init__()\n",
    "\n",
    "    # encoder\n",
    "    # (3, 64, 64)\n",
    "    self.conv1 = nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1)\n",
    "    # (32, 32, 32)\n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1)\n",
    "    # (64, 16, 16)\n",
    "    self.conv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
    "    # (128, 8, 8)\n",
    "    self.conv4 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n",
    "    # (256, 4, ,4)\n",
    "\n",
    "    self.hl1 = nn.Linear(256 * 4 * 4, 256)\n",
    "    self.hl2_mu = nn.Linear(256, 12) # mean\n",
    "    self.hl2_logvar = nn.Linear(256, 12) # log(variance)\n",
    "\n",
    "    #decoder\n",
    "    self.hl3 = nn.Linear(12, 256)\n",
    "    self.hl4 = nn.Linear(256, 256 * 4 * 4)\n",
    "\n",
    "    self.convT1 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT2 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT3 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)\n",
    "    self.convT4 = nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "  def encode(self, x) :\n",
    "    c1 = F.leaky_relu(self.conv1(x))\n",
    "    c2 = F.leaky_relu(self.conv2(c1))\n",
    "    c3 = F.leaky_relu(self.conv3(c2))\n",
    "    c4 = F.leaky_relu(self.conv4(c3))\n",
    "    h1 = F.leaky_relu(self.hl1(c4.view(-1, 256 * 4 * 4)))\n",
    "    mu = self.hl2_mu(h1)\n",
    "    logvar = self.hl2_logvar(h1)\n",
    "    logvar = torch.clamp(logvar, min=-6.0, max=6.0)\n",
    "    return mu, logvar\n",
    "\n",
    "  def reparameterize(self, mu, logvar) :\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "  def decode(self, z) :\n",
    "    h3 = F.leaky_relu(self.hl3(z))\n",
    "    h4 = F.leaky_relu(self.hl4(h3))\n",
    "    cT1 = F.leaky_relu(self.convT1(h4.view(-1, 256, 4, 4)))\n",
    "    cT2 = F.leaky_relu(self.convT2(cT1))\n",
    "    cT3 = F.leaky_relu(self.convT3(cT2))\n",
    "    cT4 = torch.sigmoid(self.convT4(cT3))\n",
    "    img = torch.clamp(cT4, min=1e-6, max=1.0)\n",
    "    return img\n",
    "\n",
    "  def forward(self, x) :\n",
    "    mu, logvar = self.encode(x)\n",
    "    z = self.reparameterize(mu, logvar)\n",
    "    recon_x = self.decode(z)\n",
    "    return recon_x, z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c67a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BetaTCVAE()\n",
    "checkpoint = torch.load(\"final_model.pth\", map_location=torch.device(device))\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee898fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(v_k, bins) :\n",
    "    counts = torch.bincount(v_k, minlength=bins)\n",
    "    prob_k = counts/counts.sum()\n",
    "    entropy = -torch.sum(prob_k[prob_k > 0] * torch.log(prob_k[prob_k > 0]))\n",
    "    \n",
    "    return entropy\n",
    "    \n",
    "def calculate_mutual_information(curr_z_discrete, curr_v, num_bins_z, curr_v_bins) :\n",
    "    N = curr_z_discrete.shape[0]\n",
    "    joint_uid = curr_z_discrete * curr_v_bins + curr_v\n",
    "    joint_counts = torch.bincount(joint_uid, minlength=num_bins_z * curr_v_bins)\n",
    "    joint_counts = joint_counts.reshape(num_bins_z, curr_v_bins)\n",
    "    P_zv = joint_counts / N\n",
    "    P_z = P_zv.sum(dim=1)\n",
    "    P_v = P_zv.sum(dim=0)\n",
    "    return P_zv, P_z, P_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a04fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting data for MIG\n",
    "\n",
    "ANALYSIS_BATCHES = 100\n",
    "\n",
    "latent_code = []\n",
    "ground_truth = []\n",
    "\n",
    "with torch.no_grad() :\n",
    "    \n",
    "    for batch_idx, (data, label) in enumerate(dataset_loader) :\n",
    "        if batch_idx >= ANALYSIS_BATCHES :\n",
    "            break\n",
    "        \n",
    "        batch = data.to(device)\n",
    "        batch_z, _ = model.encode(batch)\n",
    "        latent_code.append(batch_z.cpu())\n",
    "        ground_truth.append(label)\n",
    "        \n",
    "z = torch.cat(latent_code, dim = 0)\n",
    "v = torch.cat(ground_truth, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee35d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre processing the tensor\n",
    "\n",
    "num_bins_z = 20\n",
    "z_min = z.min(dim = 0, keepdim=True)[0]\n",
    "z_max = z.max(dim = 0, keepdim=True)[0]\n",
    "z_range = z_max - z_min\n",
    "z_range[z_range == 0] = 1.0\n",
    "z_norm = (z - z_min) / (z_range)\n",
    "z_discrete = ((num_bins_z - 1e-5) * z_norm).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae79ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the MIG matrix\n",
    "\n",
    "num_latent = z.shape[1]\n",
    "num_ground = v.shape[1]\n",
    "\n",
    "mat_mi = torch.zeros(num_latent, num_ground)\n",
    "ground_entropies = torch.zeros(num_ground)\n",
    "\n",
    "for j in range(num_ground) :\n",
    "    curr_v_float = v[:, j]\n",
    "    curr_v = torch.searchsorted(torch.unique(curr_v_float), curr_v_float)\n",
    "    curr_v_bins = int(curr_v.max().item()) + 1\n",
    "    ground_entropies[j] = calculate_entropy(curr_v, curr_v_bins)\n",
    "    \n",
    "    for i in range(num_latent) :\n",
    "        \n",
    "        curr_z = z_discrete[:, i]\n",
    "        p_zv, p_z, p_v = calculate_mutual_information(curr_z, curr_v, num_bins_z, curr_v_bins)\n",
    "        denominator = p_z.view(-1, 1) * p_v.view(1, -1)\n",
    "        arg = p_zv / denominator\n",
    "        mat_mi[i, j] = torch.sum(p_zv[p_zv > 0] * torch.log(arg[p_zv > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0090185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the gaps\n",
    "\n",
    "sorted_mi = mat_mi\n",
    "sorted_mi, _ = torch.sort(sorted_mi, dim=0, descending=True)\n",
    "best_mi_row = sorted_mi[0, :]\n",
    "second_best_mi_row = sorted_mi[1, :]\n",
    "\n",
    "gap_vec = best_mi_row - second_best_mi_row\n",
    "normalized = gap_vec / (ground_entropies +  1e-10)\n",
    "final_mig = torch.mean(normalized).item()\n",
    "print(f\"final MIG for the model : {final_mig:.4f}\")\n",
    "print(f\"individual MIG for each latent code\\n {normalized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "mi_data = mat_mi.cpu().numpy()\n",
    "\n",
    "factor_labels = ['Floor Hue', 'Wall Hue', 'Object Hue', 'Scale', 'Shape', 'Orientation']\n",
    "latent_labels = [f\"$z_{{{i}}}$\" for i in range(mi_data.shape[0])]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Mutual Information Matrix (Latents vs Factors)\", fontsize=14)\n",
    "sns.heatmap(mi_data, \n",
    "            xticklabels=factor_labels, \n",
    "            yticklabels=latent_labels, \n",
    "            annot=True, \n",
    "            fmt=\".2f\", \n",
    "            cmap=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"Ground Truth Factors\")\n",
    "plt.ylabel(\"Latent Codes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecdefec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def init_kernel(size, sigma) :\n",
    "    x = torch.arange(size).float()\n",
    "    center = size // 2\n",
    "    gaussian_1d = torch.exp(- 0.5 * ((x - center) ** 2 / sigma ** 2))\n",
    "    gaussian_1d = gaussian_1d / gaussian_1d.sum()\n",
    "    gaussian_2d = gaussian_1d.unsqueeze(1) @ gaussian_1d.unsqueeze(0)\n",
    "    return gaussian_2d.view(1, 1, size, size)\n",
    "\n",
    "def ssim(imgs1, imgs2) :\n",
    "    \n",
    "    c1 = 0.01**2\n",
    "    c2 = 0.03**2\n",
    "    \n",
    "    channel = imgs1[0].size(0)\n",
    "    window = init_kernel(11, 1.5).to(imgs1[0].device)\n",
    "    size = window.shape[2]\n",
    "    window = window.expand(channel, 1, size, size).contiguous()\n",
    "    \n",
    "    mu1 = F.conv2d(imgs1, weight=window, padding=size//2, groups=channel)\n",
    "    mu2 = F.conv2d(imgs2, weight=window, padding=size//2, groups=channel)\n",
    "    \n",
    "    mu1_sq = mu1 * mu1\n",
    "    mu2_sq = mu2 * mu2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    \n",
    "    sigma1_sq = F.conv2d(imgs1*imgs1, weight=window, padding=size//2, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(imgs2*imgs2, weight=window, padding=size//2, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(imgs1 * imgs2, weight=window, padding=size//2, groups=channel) - mu1_mu2\n",
    "    \n",
    "    \n",
    "    numerator = (2 * mu1_mu2 + c1) * (2 * sigma12 + c2)\n",
    "    denominator = (mu1_sq + mu2_sq + c1) * (sigma1_sq + sigma2_sq + c2)\n",
    "    \n",
    "    ssim_map = numerator / denominator\n",
    "    \n",
    "    return torch.mean(ssim_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad() :\n",
    "    iter_data = iter(dataset_loader)\n",
    "    batch = next(iter_data)\n",
    "    original_imgs = batch[0].to(device)\n",
    "    recon_batch, _, _, _ = model(original_imgs)\n",
    "    \n",
    "ssim_score = ssim(original_imgs, recon_batch)\n",
    "print(f\"The SSIM score of the model is : {ssim_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
